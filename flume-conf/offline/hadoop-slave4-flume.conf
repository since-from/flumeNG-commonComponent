#mq agent congfig
mqAgent.sources  = rPublic
mqAgent.sinks =  sPublicG1 sPublicG2
mqAgent.channels  = cAvro

mqAgent.sinkgroups = g1
mqAgent.sinkgroups.g1.sinks = sPublicG1 sPublicG2
mqAgent.sinkgroups.g1.processor.type = load_balance
mqAgent.sinkgroups.g1.processor.backoff = true
mqAgent.sinkgroups.g1.processor.selector = round_robin


# Bind to all interfaces
mqAgent.sources.rPublic.type  = avro
mqAgent.sources.rPublic.bind = hadoop-slave4
mqAgent.sources.rPublic.port = 8899
mqAgent.sources.rPublic.compression-type = deflate
mqAgent.sources.rPublic.channels = cAvro

# Describe  the sink
mqAgent.sinks.sPublicG1.type = elasticsearch
mqAgent.sinks.sPublicG1.hostNames  = x.x.x.x
mqAgent.sinks.sPublicG1.indexName=index
mqAgent.sinks.sPublicG1.indexType=index
mqAgent.sinks.sPublicG1.clusterName = elasticsearch
mqAgent.sinks.sPublicG1.batchSize = 5000
mqAgent.sinks.sPublicG1.serializer  = org.apache.flume.sink.elasticsearch.ElasticSearchLogStashEventSerializer
mqAgent.sinks.sPublicG1.channel = cAvro

# Describe  the sink
mqAgent.sinks.sPublicG2.type = elasticsearch
mqAgent.sinks.sPublicG2.hostNames  = x.x.x.x
mqAgent.sinks.sPublicG2.indexName=index
mqAgent.sinks.sPublicG2.indexType=index
mqAgent.sinks.sPublicG2.clusterName = elasticsearch
mqAgent.sinks.sPublicG2.batchSize = 5000
mqAgent.sinks.sPublicG2.serializer  = org.apache.flume.sink.elasticsearch.ElasticSearchLogStashEventSerializer
mqAgent.sinks.sPublicG2.channel = cAvro


# Use a  channel which buffers events in memory avro
mqAgent.channels.cAvro.type  = memory
mqAgent.channels.cAvro.capacity  = 1000000
mqAgent.channels.cAvro.transactionCapacity  = 5000
mqAgent.channels.cAvro.keep-alive = 60